\section{Introdução}
O ato de baixar automaticamente os dados de uma página web, extrair os hiperlinks contidos nela e segui-los é intitulado como Web crawler. Os dados baixados são geralmente armazenados em um índice ou banco de dados para facilitar sua busca. Web crawler, também conhecido como Indexação, é usado para indexar as informações em uma página web usando bots, também chamados de crawlers. Web Crawlers são basicamente utilizados pelos principais motores de busca como o Google, Bing e Yahoo.

Por sua vez, o ato de baixar automaticamente os dados de uma página web e extrair informações específicas dela é intitulado como Web scraping. As informações extraídas podem ser armazenadas por diferentes meios (banco de dados, arquivo, etc.). Web scraping, também conhecido como Extração de Dados da Web, é uma maneira automatizada de extrair informações/conteúdo usando bots, conhecidos como scrapers. As informações extraídas podem ser usadas para replicar em algum outro site ou podem ser usadas para análise de dados.

Na internet existem diversos pontos finais que distribuem informações não redundantes, a informação é espalhada de forma que um usuário precisa acessar cada servidor para obter informações. No tocante a portais de notícias, muitas das vezes um leitor assíduo de um determinado assunto se vê na necessidade de acessar diversos portais para inteirar-se de uma discussão através de diferentes pontos de vista ou para ficar à par de todas as novidades naquele domínio, dado que um portal pode cobrir um acontecimento que os outros portais não cobriram. Neste sentido este trabalho propõe a centralização de todas as notícias publicadas nos principais portais de notícias brasileiros acerca de um tema em uma única aplicação.

Diante do exposto, este presente trabalho prático tem por objetivo o desenvolvimento de um coletor de dados referentes ao domínio “astronomia/cosmos/espaço” em conceituados portais de notícias brasileiros utilizando técnicas de web scraping e web crawler. Para armazenar esses dados, será feito o uso de banco de dados NoSQL, extremamente aconselhável quando se está trabalhando com uma grande quantidade de dados, onde os dados não são gerados de forma estruturada. A partir desse banco de dados, será desenvolvido uma aplicação web que permitirá que usuários diversos façam as mais variadas consultas a esses dados.

Neste documento, referente à primeira etapa do trabalho, será descrito tecnicamente o coletor e o modelo conceitual do banco de dados.

